<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Notes on Let&#39;s fuck</title>
    <link>https://langyuyi.github.io/note/</link>
    <description>Recent content in Notes on Let&#39;s fuck</description>
    <generator>Hugo</generator>
    <language>en-us</language>
    <lastBuildDate>Tue, 24 Sep 2024 00:00:00 +0000</lastBuildDate>
    <atom:link href="https://langyuyi.github.io/note/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Chinese | My Deep Learning Note</title>
      <link>https://langyuyi.github.io/note/2024/09/24/another-note/</link>
      <pubDate>Tue, 24 Sep 2024 00:00:00 +0000</pubDate>
      <guid>https://langyuyi.github.io/note/2024/09/24/another-note/</guid>
      <description>神经网络基础 神经网络(Artificial Neural Network, ANN)是一种通过模拟生物神经网络进行数据拟合的机器学习算法模型，超过三层的神经网络称为深度神经网络或深度学习。它由大量的人工神经元组成，这些神经元相互连接并通过权重来传递信息。 数据归一化 数据进入神经网络前需要进行归一化步骤。常用的归一化方法有$LayerNorm$、$BatchNorm$、$RMSNorm$等。 [!attention] 注意 注意：归一化与标准化是两个不同的概念。归一化是指将数据缩放到$[0, 1]$或$[-1, 1]$区间内，标准化指的是将数据转换成均值为$0$，标准差为$1$的分布。&#xA;(1) $LayerNorm$：设$x_{ij}$表示第$i$个样本的第$j$个特征，$n$为特征数量，则$LayerNorm$的计算公式为： $$ y_{ij} = \gamma \frac{x_{ij} - \frac{1}{n} \sum_{j=1}^{n} x_{ij}}{\sqrt{\frac{1}{n} \sum_{j=1}^{n} (x_{ij} - \frac{1}{n} \sum_{j=1}^{n} x_{ij})^2 + \epsilon}} + \beta $$ [!note] 注释 其中，$\epsilon$是一个小常数，用来防止除以零的情况。可学习参数$\gamma$和$\beta$进行用于缩放和平移，使得模型可以学习到最佳的归一化效果。 每个元素的值减去样本每个特征的平均值，再除以标准差，最后再进行缩放和平移。&#xA;(2) $BatchNorm$：设每个特征的均值为$μ$，方差为$σ^2$，则$BatchNorm$的计算公式为 $$ y_{ij} = \gamma \frac{x_i - \mu}{\sqrt{\sigma^2 + \epsilon}} + \beta $$ [!note] 注释 这里的$\gamma$和$\beta$是可学习的参数，对于每个特征维度都有一个对应的$\gamma$和$\beta$值。在训练过程中，这些参数会通过反向传播算法进行更新。&#xA;(3) $RMSNorm$： $$ y_{ij} = \frac{x}{\sqrt{Mean(x^2)+ε}}·γ $$ [!note] 注释 $RMSNorm$比$Layernorm$计算更简便，节约了计算速度，&#xA;前向传播过程 前向传播(Forward Propagation)指神经网络中从输入层到输出层的数据传递过程。在这个过程中，输入数据从输入神经元开始，经过多层神经元的加权求和后经过激活函数生成输出结果。具体步骤如下： ![[../封存/图片/DNN.png|400]] $$y(x)=g(\sum_{i=1}^{n}w_ix_i+b)$$ [!</description>
    </item>
    <item>
      <title></title>
      <link>https://langyuyi.github.io/note/1/01/01/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://langyuyi.github.io/note/1/01/01/</guid>
      <description>&lt;!DOCTYPE html&gt; 06 英语语法基础 fuck06 英语语法基础06 英语语法基础#英语语法 一个视频说清整个英语语法体系&#xA;语法这种东西还是要经常复习，不然容易忘&#xA;句子结构&#xA;一些奇怪的用法：&#xA;似乎副词也能作表语：比如He is abroad，他在国外&#xA;形容词也能做状语：例如He approached us happy，他高兴地走进我们&#xA;（一）成分注释 词性：名词、代词、动词、形容词、副词、介词、数词、感叹词、冠词、连词&#xA;主语成分：名词，代词，非谓语动词，从句，介词短语&#xA;谓语成分：动词&#xA;宾语成分：名词、代词、非谓语动词、从句，介词短语&#xA;定语成分：名词(&#39;s/of )、代词 （形容词性物主），介词短语、非谓语动词，从句，形容词&#xA;状语成分：副词、副词短语、介词短语、非谓语动词、从句&#xA;表语成分：名词，代词，非谓语动词，从句，形容词，介词短语&#xA;补语成分：名词、形容词&#xA;同位语成分：名词、代词、非谓语动词、从句@至少有一个主语 @只能有一个有时态的实义动词或系动词存在且充当谓语 @情态动词不能作谓语 @副词无论在哪都做状语&#xA;注释 主语为名词和代词，谓语为动词&#xA;宾语为名词和代词，和主语一样，以外宾语与主语性质相同&#xA;定语为名词、代词和形容词&#xA;状语为副词&#xA;而非谓语动词、从句、介词短语啥都能充当，因此，当分析长难句时，NPC是难点与关键&#xA;理解非谓语动词：&#xA;三种非谓语动词：1 to eat 2 eating 3 eaten&#xA;非谓语动词有着动词的意思，但不被当作动词，当我们使用非谓语动词时，我们讨论的是动词所对应的动作本身&#xA;非谓语动词相比时态，没有表达时间，只表达了状态&#xA;（二）简单句 主+谓 主+谓+宾 主+谓+表 注释 表语又叫做主语补语，主谓表结构与主谓宾结构的区别在于后者的谓词是实义动词，前者的动词是系动词，即赋予主语意义的动词，划等号的意思。常用的系动词有以下几类：&#xA;① be动词:am/is/are/was/were&#xA;② 感官动词:look/sound/taste/smell/feel&#xA;③ 变化动词:get/become/turn/grow/fall&#xA;④ 静止动词:keep/stay/remain/stand&#xA;主+谓+宾+宾 主+谓+宾+补 @补语又叫做宾语补语 @在宾语之间加be动词意思对就是主谓宾补否则就是主谓双宾 （三）并列句：简单句+并列词+简单句 ① 平行：and,not only.</description>
    </item>
  </channel>
</rss>
